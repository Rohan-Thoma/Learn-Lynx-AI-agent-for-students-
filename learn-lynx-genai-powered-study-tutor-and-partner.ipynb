{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":97258,"sourceType":"competition"},{"sourceId":11376000,"sourceType":"datasetVersion","datasetId":7122123}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Learn-Lynx: An fun and interactive GenAI-Powered Study Partner/Tutor for students \n\n### Gen AI Intensive Course Capstone 2025Q1\n\nCapstone requirements: https://www.kaggle.com/competitions/gen-ai-intensive-course-capstone-2025q1\n\n## ğŸ§‘ğŸ½â€ğŸ’» Authors:\n- Rohan Vailala Thoma: [Kaggle-rohanthoma](https://www.kaggle.com/rohanthoma) | [LinkedIn](https://www.linkedin.com/in/rohan-vailala-thoma/)\n- Aditya Suryawanshi: [Kaggle-adii14](https://www.kaggle.com/adii14) \n- Harshitha: [Kaggle-harsh1tha](https://www.kaggle.com/harsh1tha) \n\n## ğŸ¯ Problem Statement\n\nWith exams just around the corner, students often face immense pressure to prepare effectively in a short time. Traditional study methods lack personalization and interactivity, making it hard to stay engaged. Moreover, human teachers arenâ€™t available 24/7 to answer doubts or guide last-minute revisions. This leads to stress, inefficiency, and wasted timeâ€”leaving little room for extracurriculars or relaxation.\n\nStudents need a smarter way to prepare fast, stay motivated, and reduce exam anxietyâ€”all while balancing their overall well-being.\n\n## ğŸ’¡ Our Solution\n\n**Learn-Lynx** is a GenAI-powered study assistant designed to make exam prep fast, fun, and stress-free. It provides **personalized learning plans**, **instant doubt resolution**, and **interactive quizzes** tailored to the studentâ€™s syllabus. Available 24/7, StudyMate ensures no question goes unanswered, while gamified features keep students engaged and motivatedâ€”even with just two days left for the exam.\n\nBy combining the power of the state of the art **Google's gemini AI agentic framework**, StudyMate helps students focus on what matters most, saving time for hobbies and self-care. \n\n### ğŸ”§ How It Works\n\n#### ğŸ”¶**1. Knowledge Base Creation with ChromaDB**\nAt the heart of LearnLynx lies a robust knowledge ingestion and retrieval system powered by **ChromaDB**, a vector database. Here's how it works:\n\n- **Textbook Ingestion**:  \n  Students can upload their textbooks or study materials in **PDF format** directly into the system. These documents are then processed and converted into vector embeddings using advanced natural language processing (NLP) techniques.\n  \n- **Vector Database Storage**:  \n  The processed embeddings are stored in **ChromaDB**, creating a structured and searchable knowledge base tailored to the student's syllabus. This ensures that all interactions with LearnLynx are contextually relevant and personalized.\n\n\n#### ğŸ”¶**2. Question Generation and Interactive Quizzes**\nLearnLynx doesn't just stop at storing informationâ€”it actively engages students through dynamic quizzes and interactive sessions.\n\n- **Q&A Generation**:  \n  Using the ingested textbook data, LearnLynx generates **contextual questions and answers** to test the student's understanding. These questions are crafted using the **function-calling feature** of the Gemini Agentic Framework, ensuring accuracy and relevance.\n\n- **Interactive Quiz Mode**:  \n  Instead of static Q&A, LearnLynx offers an **interactive quiz session** where students answer questions live. The AI agent evaluates the responses in real-time, providing instant feedback on whether the answer is correct or incorrect. This gamified approach keeps students engaged and motivated.\n\n\n#### ğŸ”¶**3. Summarization, Explanations, and Doubt Clearing**\nLearnLynx goes beyond simple quizzes by offering versatile tools for deeper learning:\n\n- **Summarization**:  \n  Complex topics from the uploaded textbooks are distilled into concise summaries, helping students grasp key concepts quickly.\n\n- **Topic Explanations**:  \n  If a student struggles with a topic, they can ask for detailed explanations. LearnLynx uses its **function-calling capabilities** to provide clear, step-by-step breakdowns of even the most challenging subjects.\n\n- **Doubt Resolution**:  \n  Students can ask follow-up questions during any interaction. Whether itâ€™s clarifying a concept or diving deeper into a topic, LearnLynx ensures no doubt goes unresolved.\n\n\n#### ğŸ”¶**4. Structured Query Grounding for Precision**\nTo ensure high-quality outputs, LearnLynx employs **structured query grounding** within the Gemini Agentic Framework:\n\n- **JSON Outputs**:  \n  All generated contentâ€”be it quizzes, summaries, or explanationsâ€”is formatted into precise **JSON outputs**. This guarantees clean, consistent, and machine-readable results.\n\n- **Multiple Choice Questions (MCQs)**:  \n  LearnLynx creates well-structured MCQs with clear options and answers, making it ideal for quick revisions and self-assessments.\n\n\n\n#### ğŸ”¶**5. Real-Time Web Search for Enhanced Knowledge Safety**\nOne of LearnLynxâ€™s standout features is its ability to prevent hallucinations and ensure accurate responses:\n\n- **Search Grounding**:  \n  When a question falls outside the scope of the ingested textbooks, LearnLynx leverages the **search grounding feature** of the Google GenAI Agentic Framework. It queries the web in real-time to fetch up-to-date and reliable information, ensuring the student receives accurate answers without errors.\n\n- **Knowledge Safety**:  \n  By combining internal knowledge (textbooks) with external search capabilities, LearnLynx eliminates the risk of misinformation, prioritizing the studentâ€™s learning integrity.\n\n\n#### ğŸ”¶**6. Conversational Flexibility**\nLearnLynx offers a seamless conversational experience:\n\n- **Interactive Dialogue**:  \n  Students can engage in natural, back-and-forth conversations with the AI. They can ask follow-up questions, request further explanations, or exit the chat whenever they want.\n\n- **Customizable Learning Paths**:  \n  Based on the studentâ€™s performance in quizzes and their specific doubts, LearnLynx adapts to create a personalized learning path, ensuring maximum efficiency.\n\n\n\n#### ğŸ† **Why LearnLynx Stands Out**\nLearnLynx combines several state-of-the-art technologies and methodologies to deliver a truly unique and effective learning experience:\n\n- **Engagement Through Interactivity**: The live quiz feature transforms passive studying into an active, enjoyable process.\n- **Personalization**: Tailored to the studentâ€™s syllabus and learning pace, ensuring relevance and effectiveness.","metadata":{}},{"cell_type":"markdown","source":"## ğŸ¤– GenAI Capabilities\n\n- Structured output/JSON mode/controlled generation\n- Few-shot prompting\n- Document understanding\n- Function Calling\n- Agents\n- Long context window\n- Context caching\n- Gen AI evaluation\n- Grounding\n- Embeddings\n- Retrieval augmented generation (RAG)\n- Vector search/vector store/vector database","metadata":{}},{"cell_type":"markdown","source":"### ğŸ“² Installing the SDK \nInstalling the ChromaDB, Gemini API python SDK, langchain and pdfplumber etc which are needed for this capstone project","metadata":{}},{"cell_type":"code","source":"!pip uninstall -qqy jupyterlab  # Remove unused packages from Kaggle's base image that conflict\n!pip install -U -q \"google-genai==1.7.0\"\n!pip install -U -q pdfplumber tiktoken \"chromadb==0.6.3\" \n!pip install -U langchain-community","metadata":{"execution":{"iopub.status.busy":"2025-04-21T04:10:57.982509Z","iopub.execute_input":"2025-04-21T04:10:57.982972Z","iopub.status.idle":"2025-04-21T04:11:56.958501Z","shell.execute_reply.started":"2025-04-21T04:10:57.982936Z","shell.execute_reply":"2025-04-21T04:11:56.957127Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m144.7/144.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m100.9/100.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\njupyterlab-lsp 3.10.2 requires jupyterlab<4.0.0a0,>=3.1.0, which is not installed.\u001b[0m\u001b[31m\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m611.1/611.1 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.2/60.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m188.4/188.4 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.3/65.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m119.0/119.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m89.1/89.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.4 which is incompatible.\ngoogle-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 5.29.4 which is incompatible.\ngoogle-spark-connect 0.5.2 requires google-api-core>=2.19.1, but you have google-api-core 1.34.1 which is incompatible.\npandas-gbq 0.26.1 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ngoogle-cloud-bigtable 2.28.1 requires google-api-core[grpc]<3.0.0dev,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mCollecting langchain-community\n  Downloading langchain_community-0.3.21-py3-none-any.whl.metadata (2.4 kB)\nCollecting langchain-core<1.0.0,>=0.3.51 (from langchain-community)\n  Downloading langchain_core-0.3.54-py3-none-any.whl.metadata (5.9 kB)\nCollecting langchain<1.0.0,>=0.3.23 (from langchain-community)\n  Downloading langchain-0.3.23-py3-none-any.whl.metadata (7.8 kB)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.38)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.16)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\nCollecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\nRequirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.8)\nCollecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\nRequirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.19.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\nCollecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain<1.0.0,>=0.3.23->langchain-community)\n  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.23->langchain-community) (2.11.3)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (1.33)\nRequirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (24.2)\nRequirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (4.13.1)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.15)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.2->langchain-community) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.2->langchain-community) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.2->langchain-community) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.2->langchain-community) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.2->langchain-community) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.2->langchain-community) (2.4.1)\nRequirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.1.31)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain-community) (3.0.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain-community) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain-community) (2.33.1)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3,>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3,>=1.26.2->langchain-community) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3,>=1.26.2->langchain-community) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3,>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3,>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\nDownloading langchain_community-0.3.21-py3-none-any.whl (2.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\nDownloading langchain-0.3.23-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_core-0.3.54-py3-none-any.whl (433 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m433.9/433.9 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\nInstalling collected packages: httpx-sse, pydantic-settings, langchain-core, langchain-text-splitters, langchain, langchain-community\n  Attempting uninstall: langchain-core\n    Found existing installation: langchain-core 0.3.35\n    Uninstalling langchain-core-0.3.35:\n      Successfully uninstalled langchain-core-0.3.35\n  Attempting uninstall: langchain-text-splitters\n    Found existing installation: langchain-text-splitters 0.3.6\n    Uninstalling langchain-text-splitters-0.3.6:\n      Successfully uninstalled langchain-text-splitters-0.3.6\n  Attempting uninstall: langchain\n    Found existing installation: langchain 0.3.18\n    Uninstalling langchain-0.3.18:\n      Successfully uninstalled langchain-0.3.18\nSuccessfully installed httpx-sse-0.4.0 langchain-0.3.23 langchain-community-0.3.21 langchain-core-0.3.54 langchain-text-splitters-0.3.8 pydantic-settings-2.9.1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"Import the SDK and some helpers for rendering the output.","metadata":{}},{"cell_type":"code","source":"from google import genai\nfrom google.genai import types\nfrom IPython.display import HTML, Markdown, display\n\ngenai.__version__\n","metadata":{"execution":{"iopub.status.busy":"2025-04-21T04:11:56.960646Z","iopub.execute_input":"2025-04-21T04:11:56.960966Z","iopub.status.idle":"2025-04-21T04:11:58.551738Z","shell.execute_reply.started":"2025-04-21T04:11:56.960938Z","shell.execute_reply":"2025-04-21T04:11:58.550874Z"},"trusted":true},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'1.7.0'"},"metadata":{}}],"execution_count":2},{"cell_type":"markdown","source":"Set up a retry helper. This allows you to \"Run all\" without worrying about per-minute quota.","metadata":{}},{"cell_type":"code","source":"from google.api_core import retry\nis_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n\ngenai.models.Models.generate_content = retry.Retry(\n    predicate=is_retriable)(genai.models.Models.generate_content)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T04:11:58.552692Z","iopub.execute_input":"2025-04-21T04:11:58.553239Z","iopub.status.idle":"2025-04-21T04:11:58.728873Z","shell.execute_reply.started":"2025-04-21T04:11:58.553211Z","shell.execute_reply":"2025-04-21T04:11:58.728083Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"### âš™ï¸ Set up the API key","metadata":{}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"my-api\")\n\nclient = genai.Client(api_key=GOOGLE_API_KEY)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T04:11:58.729858Z","iopub.execute_input":"2025-04-21T04:11:58.730375Z","iopub.status.idle":"2025-04-21T04:11:59.297675Z","shell.execute_reply.started":"2025-04-21T04:11:58.730338Z","shell.execute_reply":"2025-04-21T04:11:59.296627Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"### ğŸ§© GeminiEmbeddingFunction (class)\n**Purpose** : Defines how to get vector embeddings for text using Google's Gemini embedding model.\n\n**Used For** : Semantic similarity, document retrieval, etc.\n\n**Key Features**:\n- Supports both query and document embeddings (retrieval_query or retrieval_document).\n- Uses a retry mechanism in case of temporary API failures.\n- Returns a list of embeddings from the Gemini model.","metadata":{}},{"cell_type":"code","source":"import os\nimport glob\nimport pdfplumber\nfrom chromadb import Documents, EmbeddingFunction, Embeddings\n\npdf_folder_path = \"/kaggle/input/ebook-pdfs\"\n# pdf_folder_path = \"/mnt/d/All_Desk/Google GEN-AI/Data/trimmed-pdfs\"\n\n\nclass GeminiEmbeddingFunction(EmbeddingFunction):\n    document_mode = True\n\n    @retry.Retry(predicate=is_retriable)\n    def __call__(self, input: Documents) -> Embeddings:\n        embedding_task = \"retrieval_document\" if self.document_mode else \"retrieval_query\"\n        response = client.models.embed_content(\n            model=\"models/text-embedding-004\",\n            contents=input,\n            config=types.EmbedContentConfig(task_type=embedding_task),\n        )\n        return [e.values for e in response.embeddings]","metadata":{"execution":{"iopub.status.busy":"2025-04-21T04:20:28.619873Z","iopub.execute_input":"2025-04-21T04:20:28.620218Z","iopub.status.idle":"2025-04-21T04:20:28.627010Z","shell.execute_reply.started":"2025-04-21T04:20:28.620183Z","shell.execute_reply":"2025-04-21T04:20:28.625990Z"},"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"### ğŸ§¹ Cleaning the text to avoid redundant vectors in the database\n**Purpose**: Cleans up raw text before chunking or embedding.\n\n**Removes**:\n\n- URLs\n\n- Non-alphabet characters\n\n- Custom stopwords (like \"chapter\", \"figure\", etc.)\n\n- ALL CAPS words (likely headings or noise)\n\n**Returns**: A cleaner version of the input text for better embedding quality.","metadata":{}},{"cell_type":"code","source":"# Function to load and chunk PDFs from folder\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom tqdm import tqdm \nimport re\n\n# Define your custom stopword list\nCUSTOM_STOPWORDS = {\n    \"openstax\", \"figure\", \"access\", \"free\", \"chapter\", \"outline\", \"learning\", \n    \"objectives\", \"link\", \"visual\", \"connection\", \"evolution\", \"career\"\n}\n\ndef clean_text(text: str, stopwords: set = CUSTOM_STOPWORDS) -> str:\n    text = re.sub(r'https?://\\S+|www\\.\\S+|\\S+\\.com\\S*', '', text)\n    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n    text = re.sub(r'\\s+', ' ', text).strip()\n    words = text.split()\n\n    # Filter out custom stopwords and ALL CAPS words\n    cleaned_words = [\n        word for word in words\n        if word.lower() not in stopwords and not word.isupper()\n    ]\n\n    return ' '.join(cleaned_words)\n","metadata":{"execution":{"iopub.status.busy":"2025-04-21T04:12:00.004334Z","iopub.execute_input":"2025-04-21T04:12:00.004690Z","iopub.status.idle":"2025-04-21T04:12:00.048748Z","shell.execute_reply.started":"2025-04-21T04:12:00.004642Z","shell.execute_reply":"2025-04-21T04:12:00.047968Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"### ğŸ« Chunking and loading the pdf's in the database\n**Purpose**:\n\n- Loads all .pdf files from a folder.\n\n- Extracts and cleans text from each page.\n\n- Splits the cleaned text into overlapping chunks.\n\n**Why**:\n\nLarge documents need to be split into smaller chunks for embedding and querying (e.g., in vector databases).\n\n**Tools Used**:\n\n- pdfplumber: Extracts text from PDF.\n\n- RecursiveCharacterTextSplitter: Splits text into chunks with overlap for context retention.\n\n- tqdm: Progress bar for PDF processing.","metadata":{}},{"cell_type":"code","source":"# Function to load and chunk PDFs from folder\ndef load_and_chunk_pdfs(folder_path: str, chunk_size: int = 2000, chunk_overlap: int = 800) -> list[str]:\n    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n    all_chunks = []\n\n    for filename in os.listdir(folder_path):\n        if filename.endswith(\".pdf\"):\n            file_path = os.path.join(folder_path, filename)\n            with pdfplumber.open(file_path) as pdf:\n                full_text = \"\"\n                for page in tqdm(pdf.pages):\n                    page_text = page.extract_text()\n                    if page_text:\n                        cleaned_text = clean_text(page_text)\n                        full_text += cleaned_text + \"\\n\"\n\n                chunks = splitter.split_text(full_text)\n                all_chunks.extend(chunks)\n\n    return all_chunks","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T04:12:00.049661Z","iopub.execute_input":"2025-04-21T04:12:00.050308Z","iopub.status.idle":"2025-04-21T04:12:00.056471Z","shell.execute_reply.started":"2025-04-21T04:12:00.050281Z","shell.execute_reply":"2025-04-21T04:12:00.055389Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Load and chunk PDF text\nchunked_documents = load_and_chunk_pdfs(pdf_folder_path)","metadata":{"execution":{"iopub.status.busy":"2025-04-21T04:12:00.057570Z","iopub.execute_input":"2025-04-21T04:12:00.058047Z","iopub.status.idle":"2025-04-21T04:18:27.473105Z","shell.execute_reply.started":"2025-04-21T04:12:00.058008Z","shell.execute_reply":"2025-04-21T04:18:27.472407Z"},"trusted":true},"outputs":[{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1451/1451 [04:28<00:00,  5.40it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 584/584 [00:16<00:00, 36.09it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 531/531 [01:33<00:00,  5.66it/s]\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"### ğŸ“š This setup is part of a Retrieval-Augmented Generation (RAG) or semantic search system:\n\n- **Indexing step**: PDFs are chunked, embedded, and stored in ChromaDB.\n\n- **Querying step (enabled by switching to query mode)**: A user input can be embedded and compared against stored document embeddings to retrieve semantically similar chunks.\n\nThis code initializes a Chroma vector database and stores text chunks (from processed PDFs) by embedding them using a custom GeminiEmbeddingFunction in document mode. It creates or retrieves a Chroma collection named google_pdf_db, generates unique IDs for each chunk, and adds the chunks in batches of 10 for efficient storage. After storing the document embeddings, it switches the embedding function to query mode, preparing it for semantic search where user queries can be embedded and matched against the stored document vectors.","metadata":{}},{"cell_type":"code","source":"# Initialize ChromaDB and embed\nimport chromadb\nfrom tqdm import tqdm \n\n# Initialize ChromaDB and embed\nDB_NAME = \"google_pdf_db\"\nembed_fn = GeminiEmbeddingFunction()\nembed_fn.document_mode = True\n\nchroma_client = chromadb.Client()\ndb = chroma_client.get_or_create_collection(name=DB_NAME, embedding_function=embed_fn)\n\n# Add chunked docs to the DB\nids = [str(i) for i in range(len(chunked_documents))]\nfor i in tqdm(range(0, len(chunked_documents), 10), desc=\"Adding to ChromaDB\"):\n    db.add(documents=chunked_documents[i:i+10], ids=ids[i:i+10])\n\n# Switch to query mode\nembed_fn.document_mode = False\n","metadata":{"execution":{"iopub.status.busy":"2025-04-21T04:26:39.287892Z","iopub.execute_input":"2025-04-21T04:26:39.288278Z","iopub.status.idle":"2025-04-21T04:31:18.443451Z","shell.execute_reply.started":"2025-04-21T04:26:39.288254Z","shell.execute_reply":"2025-04-21T04:31:18.442714Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Adding to ChromaDB: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 383/383 [04:39<00:00,  1.37it/s]\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"### ğŸ¤” Query functions both with and without grounding\n### **query_context(query)**\n- **Purpose**: Performs a **semantic search** in the local ChromaDB using the query.\n- **How it works**:\n  - Uses the `query` as input to ChromaDBâ€™s `.query()` method.\n  - Retrieves the **top 10 most relevant document chunks** (`n_results=10`).\n  - Joins the retrieved passages into a single string (separated by double newlines).\n- **Use Case**: Fast, offline access to relevant information from the indexed documents.\n\n### **query_with_grounding(query)**\n- **Purpose**: Falls back to **real-time, web-grounded generation** using Gemini if local context isnâ€™t sufficient.\n- **How it works**:\n  - Sends the query to Gemini with **Google Search enabled** (`google_search_tool`).\n  - Receives a natural language response from the model, potentially enriched with web content.\n- **Use Case**: Useful when local documents lack relevant information or need to be supplemented with up-to-date facts.\n\nTogether, these functions allow hybrid retrieval: first from local vector DB, and then from the web when needed.","metadata":{}},{"cell_type":"code","source":"# Dynamic query functions\n\n# Enable Google Search tool\ngoogle_search_tool = types.Tool(google_search=types.GoogleSearch())\nconfig_with_search = types.GenerateContentConfig(tools=[google_search_tool])\n\ndef query_context(query):\n    result = db.query(query_texts=[query], n_results=10)\n    [all_passages] = result[\"documents\"]\n    return \"\\n\\n\".join(all_passages)\n\n# Try search grounding if local context fails\ndef query_with_grounding(query):\n    response = client.models.generate_content(\n        model='gemini-2.0-flash',\n        contents=query,\n        config=config_with_search,\n    )\n    return response.candidates[0].content.parts[0].text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T04:31:24.178818Z","iopub.execute_input":"2025-04-21T04:31:24.179130Z","iopub.status.idle":"2025-04-21T04:31:24.185925Z","shell.execute_reply.started":"2025-04-21T04:31:24.179105Z","shell.execute_reply":"2025-04-21T04:31:24.185128Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"### ğŸ“¢ **Summarizing any topic using given context using RAG**\n- **Purpose**: Summarizes a given topic using local document data or falls back to web-based summarization.\n- **How it works**:\n  - Calls `query_context(topic)` to fetch relevant context from ChromaDB.\n  - If no context is found, it prints a message and uses `query_with_grounding()` to summarize via Google Search + Gemini.\n  - If context is found, it builds a prompt with the context and sends it to Gemini to generate a summary.\n- **Use Case**: Smart summarization that prioritizes local knowledge but adapts to online sources if needed.\n","metadata":{}},{"cell_type":"code","source":"# Smart summarizer with fallback\ndef summarize_topic(topic):\n    context = query_context(topic)\n    if not context.strip():\n        print(\"ğŸ” No relevant content found locally. Trying grounded web search...\")\n        return query_with_grounding(f\"Summarize this topic: {topic}\")\n    prompt = f\"\"\"Using the below context, summarize the topic: {topic}\\n\\nContext:\\n{context}\"\"\"\n    response = client.models.generate_content(model=\"gemini-2.0-flash\", contents=prompt)\n    return response.text\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T04:31:29.465422Z","iopub.execute_input":"2025-04-21T04:31:29.465722Z","iopub.status.idle":"2025-04-21T04:31:29.471529Z","shell.execute_reply.started":"2025-04-21T04:31:29.465699Z","shell.execute_reply":"2025-04-21T04:31:29.470316Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"\n### â˜‘ï¸ **Checking user response for an answer**\n- **Purpose**: Detects if a given message is likely an **answer to a multiple-choice question**.\n- **How it works**:\n  - Sends a Yes/No prompt to Gemini, asking if the input message looks like a multiple-choice answer.\n  - Returns `True` if Geminiâ€™s response starts with \"yes\".\n- **Use Case**: Useful for auto-validating if a student or user input looks like an attempted answer.\n","metadata":{}},{"cell_type":"code","source":"# Gemini prompt to detect if response is an answer\ndef is_probable_answer(text):\n    check_prompt = f\"Is the following user message an answer to a multiple choice question?\\n\\nMessage: {text}\\n\\nRespond with 'Yes' or 'No'.\"\n    r = client.models.generate_content(model=\"gemini-2.0-flash\", contents=check_prompt)\n    return r.text.strip().lower().startswith(\"yes\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T04:31:33.627200Z","iopub.execute_input":"2025-04-21T04:31:33.627514Z","iopub.status.idle":"2025-04-21T04:31:33.632482Z","shell.execute_reply.started":"2025-04-21T04:31:33.627491Z","shell.execute_reply":"2025-04-21T04:31:33.631655Z"}},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"\n### â˜‘ï¸**Checking the user response for a query**\n- **Purpose**: Checks if the user message is likely **asking for an explanation or summary**.\n- **How it works**:\n  - Sends a Yes/No prompt to Gemini, asking if the message is a request for explanation.\n  - Returns `True` if the response starts with \"yes\".\n- **Use Case**: Helps identify when users need concept clarification, enabling smart routing of queries.","metadata":{}},{"cell_type":"code","source":"# Gemini prompt to detect if response is asking for explanation\ndef is_probably_explanation_request(text):\n    check_prompt = f\"Is the following user message asking for an explanation or summary of a concept?\\n\\nMessage: {text}\\n\\nRespond with 'Yes' or 'No'.\"\n    r = client.models.generate_content(model=\"gemini-2.0-flash\", contents=check_prompt)\n    return r.text.strip().lower().startswith(\"yes\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T04:31:36.712742Z","iopub.execute_input":"2025-04-21T04:31:36.713059Z","iopub.status.idle":"2025-04-21T04:31:36.718180Z","shell.execute_reply.started":"2025-04-21T04:31:36.713038Z","shell.execute_reply":"2025-04-21T04:31:36.717222Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"### ğŸ™‹ğŸ½ Generating MCQs Using Prompting\n\nThis function helps generate **Multiple Choice Questions (MCQs)** using the **Gemini AI model** by giving it a clear prompt and formatting instructions.\n\n- We set some model configuration to control how creative the output should be.\n- The prompt tells the model to:\n  - Read the given **context** (like a topic or notes),\n  - Create **4 MCQs** with 4 options each,\n  - Mark **1 correct answer** per question,\n  - Return everything in a **structured JSON format**.\n- We send this prompt to Gemini and get back a text response.\n- The response is cleaned up to remove extra formatting (like ```json).\n- Finally, the JSON string is parsed into a Python object (list of dictionaries) that we can use in our app.\n\nThis is an example of **controlled output via prompting** â€” where we guide the AI to give us a very specific type of response.","metadata":{}},{"cell_type":"code","source":"# Build prompt for Gemini to generate MCQs\nimport json\nmodel_config = types.GenerateContentConfig(\n    # These are the default values for gemini-2.0-flash.\n    temperature=1.0,\n    top_p=0.95,\n)\ndef generate_mcqs(context):\n  prompt = f\"\"\"\n  Using the context below, generate 4 multiple choice questions with 4 options and 1 correct answer each:\n\n  Context:\n  {context}\n\n  Format:\n  [\n    {{\n      \"question\": \"...\",\n      \"options\": [\"A\", \"B\", \"C\", \"D\"],\n      \"answer\": \"C\"\n    }},\n    ...\n  ]\n  \"\"\"\n  response = client.models.generate_content(\n      model=\"gemini-2.0-flash\",\n      config= model_config,\n      contents=prompt\n  )\n\n  raw_string = response.text\n\n  # Remove the ```json and ``` markers\n  cleaned = raw_string.strip('`').split('\\n', 1)[1].rsplit('\\n', 1)[0]\n  return json.loads(cleaned)\n\n# print(generate_mcqs(context))","metadata":{"execution":{"iopub.status.busy":"2025-04-21T04:31:43.933271Z","iopub.execute_input":"2025-04-21T04:31:43.933587Z","iopub.status.idle":"2025-04-21T04:31:43.939822Z","shell.execute_reply.started":"2025-04-21T04:31:43.933564Z","shell.execute_reply":"2025-04-21T04:31:43.938993Z"},"trusted":true},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"### ğŸ¤– Interactive Q&A Quiz with Smart Answer Checking\n\nThis code demonstrates a unique and engaging **study experience** with a sample query where students can actively participate in a quiz *and* ask questions along the way â€” all in a single session!\n\n### âœ¨ What It Does\n\n- **Generates MCQs from Study Material**  \n  Based on a topic or user query, the system pulls relevant content and uses an AI model to create multiple-choice questions automatically.\n\n- **Interactive Quiz Mode**  \n  The student is presented with questions one by one, with four answer options each. They can answer by choosing A/B/C/D, and the system instantly checks if the answer is correct.\n\n- **Flexible Question-Answering Anytime**  \n  At any point, the student can type a free-form question like *\"Explain photosynthesis\"* or *\"Summarize DNA structure\"* instead of answering the MCQ.  \n  The assistant detects this and switches to **explanation mode** to provide a detailed answer.\n\n- **Seamless Transition Between Modes**  \n  After answering a custom question, the system smoothly returns to the quiz right where it left off â€” maintaining a natural flow of learning.\n\n### ğŸŒŸ Why Itâ€™s Special\n\n- Blends **quiz-based learning** with **free-form exploration**.\n- Encourages **active recall** while supporting **curiosity-driven questions**.\n- Offers **immediate feedback** and keeps the learner engaged.\n- Makes the learning process feel like a conversation with a helpful tutor.\n\nThis approach is great for creating an **AI-powered study assistant** thatâ€™s not just about testing, but truly helps the student understand and retain concepts at their own pace.\n","metadata":{}},{"cell_type":"code","source":"# Sample query\nquery = \"How does photosynthesis in plants work and what is the role of chlorophyl in photosynthesis, explain in detail with examples?\"\nresult = db.query(query_texts=[query], n_results=10)\n\n# Build prompt for Gemini to generate MCQs\n[all_passages] = result[\"documents\"]\ncontext = \"\\n\\n\".join(all_passages)\n\n# Interactive Q&A mode with chat interface\ndef qa_loop():\n    print(\"\\nğŸ‘‹ Welcome to the Quiz Mode! Type 'exit' at any time to quit.\")\n    print(\"You can also type something like 'Explain photosynthesis' or 'Summarize DNA structure'.\\n\")\n    questions = generate_mcqs(context)\n    i=0\n    while(i<len(questions)):\n    # for i in range(len(questions)):\n        q= questions[i]\n        print(i+1,\". \",q[\"question\"])\n        opt_list = [\"A. \",\"B. \",\"C. \",\"D. \"]\n        for j,opt in enumerate(q[\"options\"]):\n            print(f\"{opt_list[j]}{opt}\")\n        while True:\n            user_input = input(\"Your answer (A/B/C/D) or query: \").strip()\n            if user_input.lower() == \"exit\":\n                print(\"\\nğŸ‘‹ Thanks for playing! Exiting Q&A mode.\\n\")\n                return\n            if not is_probable_answer(user_input) and is_probably_explanation_request(user_input):\n                print(\"\\nğŸ§  Switching to explanation mode...\\n\")\n                print(summarize_topic(user_input))\n                print(\"\\nReturning to Q&A mode...\\n\")\n                break\n            if user_input.upper() == q[\"answer\"].upper():\n                print(f\"âœ… Correct!\\n {user_input.upper()} is the answer\")\n                i+=1\n                break\n            else:\n                print(\"âŒ Incorrect. Try again or say anything else to switch mode.\")\n\nqa_loop()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T04:31:55.888565Z","iopub.execute_input":"2025-04-21T04:31:55.889191Z","iopub.status.idle":"2025-04-21T04:33:00.435411Z","shell.execute_reply.started":"2025-04-21T04:31:55.889148Z","shell.execute_reply":"2025-04-21T04:33:00.434421Z"}},"outputs":[{"name":"stdout","text":"\nğŸ‘‹ Welcome to the Quiz Mode! Type 'exit' at any time to quit.\nYou can also type something like 'Explain photosynthesis' or 'Summarize DNA structure'.\n\n1 .  Which of the following processes allows atoms to de-excite in smaller steps, emitting energy different from that which excited it?\nA. A. Phosphorescence\nB. B. Absorption\nC. C. Fluorescence\nD. D. Blackbody Radiation\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Your answer (A/B/C/D) or query:  B\n"},{"name":"stdout","text":"âŒ Incorrect. Try again or say anything else to switch mode.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Your answer (A/B/C/D) or query:  C\n"},{"name":"stdout","text":"âœ… Correct!\n C is the answer\n2 .  Which type of cells have DNA that is not enclosed within a nucleus?\nA. A. Animal\nB. B. Plant\nC. C. Prokaryotic\nD. D. Eukaryotic\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Your answer (A/B/C/D) or query:  what is a nucleus?\n"},{"name":"stdout","text":"\nğŸ§  Switching to explanation mode...\n\nThe nucleus is the central part of an atom containing protons (positively charged particles) and neutrons (neutral particles).  Protons and neutrons are collectively called nucleons.  A specific combination of protons and neutrons is called a nuclide, which defines a unique nucleus. The number of protons is the atomic number, while the total number of protons and neutrons is the mass number.\n\n\nReturning to Q&A mode...\n\n2 .  Which type of cells have DNA that is not enclosed within a nucleus?\nA. A. Animal\nB. B. Plant\nC. C. Prokaryotic\nD. D. Eukaryotic\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Your answer (A/B/C/D) or query:  C\n"},{"name":"stdout","text":"âœ… Correct!\n C is the answer\n3 .  What is the process where plants convert radiant heat transfer in sunlight to stored chemical energy?\nA. A. Metabolism\nB. B. Fermentation\nC. C. Photosynthesis\nD. D. Citric Acid Cycle\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Your answer (A/B/C/D) or query:  exit\n"},{"name":"stdout","text":"\nğŸ‘‹ Thanks for playing! Exiting Q&A mode.\n\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"### ğŸ’¬ Study Assistant: Friendly Chat Mode for Doubts, Plans & More\n\nThis section powers the **main chat experience** of the AI Study Assistant â€” a space where students can interact with the AI just like chatting with a real tutor.\n\n\n### ğŸ§  What It Offers\n\n- **Natural Conversation Flow**  \n  Students can type their questions, thoughts, or study needs in plain language â€” and the AI responds conversationally and supportively.\n\n- **Multi-Purpose Help in One Place**  \n  The assistant can:\n  - ğŸ—“ **Create a personalized study plan**\n  - â“ **Answer questions and clear doubts**\n  - ğŸ§ª **Generate custom quizzes**\n  - ğŸ“š **Summarize or explain tricky concepts**\n\n- **Smart Prompting Behind the Scenes**  \n  Even though the interface feels casual, the AI is guided by a powerful system prompt that tells it how to:\n  - Stay friendly and age-appropriate,\n  - Explain topics clearly,\n  - Avoid unnecessary technical jargon,\n  - Provide structured and helpful outputs.\n\n- **All-in-One Input Style**  \n  The assistant can respond based on:\n  - Uploaded notes, textbook content, or typed queries,\n  - Learning goals and time constraints,\n  - Studentâ€™s level of knowledge (if provided).\n\n\n### ğŸŒŸ Why This Is Awesome\n\n- Makes studying feel more like **chatting with a mentor** than using a tool.\n- Helps students feel **supported and encouraged**, not judged.\n- Great for both **deep learning** and **quick clarifications**.\n- Students can explore topics freely *outside* of quiz mode.\n\n\n### ğŸ›‘ Exit Gracefully\n\nWhen the student types `exit`, they get a warm farewell with a motivational nudge â€” reinforcing a **positive learning experience** every time.\n\nThis mode turns the AI into a **friendly study buddy**, ready to assist at any point in the studentâ€™s learning journey â€” no pressure, just progress.","metadata":{}},{"cell_type":"code","source":"model_config = types.GenerateContentConfig(\n    # These are the default values for gemini-2.0-flash.\n    temperature=1.0,\n    top_p=0.95,\n    max_output_tokens=700\n)\n\ndef chat(query):\n    prompt = f\"\"\"\n    You are an interactive AI-powered study assistant named Learn-Lynx designed to help students learn more effectively. Your role is to support students by performing the following key functions:\n\n    1. **Study Plan Generation**  \n    - Create customized study plans based on the student's syllabus, goals, available time, and preferred pace.  \n    - Break down subjects into manageable chunks with deadlines and revision intervals.  \n    - Adapt the plan dynamically based on progress and performance in quizzes.\n\n    2. **Quiz Generation**  \n    - Generate quizzes of various types (MCQs, short answer, true/false, etc.) based on the notes, textbooks, or topics provided.  \n    - Ensure questions vary in difficulty and cover both conceptual understanding and factual recall.  \n    - Provide immediate feedback with correct answers and explanations.\n\n    3. **Doubt Clearing & Concept Explanation**  \n    - Answer any questions the student asks from the uploaded notes, textbooks, or general topics.  \n    - Summarize complex content and explain concepts in simple, student-friendly language.  \n    - Include visual or real-world analogies where appropriate to enhance understanding.\n\n    **Input:**  \n    - Textbook excerpts, class notes, uploaded documents (PDF, DOCX, etc.), or typed queries.  \n    - Optional: studentâ€™s current level, exam date, preferred study hours per day.\n\n    **Output:**  \n    - Daily/weekly study plans with topic-wise targets.  \n    - Auto-generated quizzes with answer keys and explanations.  \n    - Clear, concise answers to doubts based on the provided materials or relevant academic sources.\n\n    **Tone:**  \n    - Supportive, friendly, and motivating.  \n    - Avoid overly technical jargon unless requested.  \n    - Ensure explanations are age-appropriate and tailored to the student's education level.\n    \n    Now, answer the following query, keeping all the above points in mind:\n    {query}\n    \"\"\"\n    response = client.models.generate_content(\n      model=\"gemini-2.0-flash\",\n      config= model_config,\n      contents=prompt\n    )\n    \n    return response.text\n\ndef chat_interface(verbose=False):\n    print(\"ğŸ“ Hey there! Welcome, I am Learn-Lynx! ğŸ“š \\n\\\nI'm here to make studying easier, smarter, and a lot more fun. Whether you need help creating a study plan, want to test your knowledge with some quizzes, or have questions from your notes or textbooks â€” Iâ€™ve got your back! ğŸ’ª\\n \\\nJust tell me what youâ€™re working on today, and letâ€™s get started! ğŸš€\")\n    convo =\"\"\n    while True:\n        user_input = input()\n        if user_input.lower() == 'exit':\n            print(\"ğŸ‘‹ Thatâ€™s a wrap for now! \\n \\\nGreat job today â€” every step you take brings you closer to your goals. ğŸ¯ \\n \\\nRemember, Iâ€™m always here whenever you need help with studying, quizzes, or clearing up doubts. \\n \\\nStay curious, keep learning, and donâ€™t forget to take a break! ğŸ˜ŒğŸ“˜ \\n \\\nSee you soon...! ğŸŒŸ\")\n            break\n        else:\n            convo = convo + user_input\n            response = chat(convo)\n            display(Markdown(response))\n\nchat_interface()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T04:34:08.596672Z","iopub.execute_input":"2025-04-21T04:34:08.597540Z","iopub.status.idle":"2025-04-21T04:34:50.041394Z","shell.execute_reply.started":"2025-04-21T04:34:08.597508Z","shell.execute_reply":"2025-04-21T04:34:50.040524Z"}},"outputs":[{"name":"stdout","text":"ğŸ“ Hey there! Welcome, I am Learn-Lynx! ğŸ“š \nI'm here to make studying easier, smarter, and a lot more fun. Whether you need help creating a study plan, want to test your knowledge with some quizzes, or have questions from your notes or textbooks â€” Iâ€™ve got your back! ğŸ’ª\n Just tell me what youâ€™re working on today, and letâ€™s get started! ğŸš€\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":" what is cell division and why is it useful?\n"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Hey there! Let's tackle cell division. I'm Learn-Lynx, your study buddy, and I'll break this down for you.\n\n**What is Cell Division?**\n\nImagine you're a single Lego brick, and you want to build a whole Lego castle. You'd need more bricks, right? Cell division is basically how cells make more of themselves. It's the process where a single cell (called the \"parent cell\") divides into two or more \"daughter cells.\" These daughter cells are usually identical (or very similar) to the parent cell.\n\nThink of it like photocopying a document - the original (parent cell) makes copies (daughter cells) of itself!\n\nThere are two main types of cell division:\n\n*   **Mitosis:** This is used for growth, repair, and asexual reproduction (making a new organism from just one parent). Think of it like patching up a scraped knee or a plant growing taller. One cell divides into two identical daughter cells.\n\n*   **Meiosis:** This is used for sexual reproduction (when two parents combine their DNA to create offspring). This is more complicated and results in four daughter cells, each with half the number of chromosomes as the parent cell. These daughter cells are called gametes (sperm and egg cells).\n\n**Why is Cell Division Useful?**\n\nCell division is ESSENTIAL for life! Here's why:\n\n*   **Growth:** From a tiny baby to a grown-up, you needed cell division to increase the number of cells in your body. It's how you get bigger!\n\n*   **Repair:** Got a cut? Cell division helps replace the damaged cells and heal the wound.\n\n*   **Replacement:** Some of your cells have a short lifespan (like skin cells). Cell division constantly replaces old or damaged cells with new ones.\n\n*   **Reproduction:** For single-celled organisms, cell division is their way of reproducing (making more of themselves). For multicellular organisms (like us!), meiosis allows for sexual reproduction, creating new individuals with a mix of genetic information from both parents. This genetic diversity is important for adaptation and survival.\n\n**In a nutshell:** Cell division is how organisms grow, repair themselves, and reproduce. Without it, life as we know it wouldn't exist!\n\nDo you want to dive deeper into mitosis or meiosis? Maybe take a quick quiz to see how well you understand the basics? Just let me know! We can also create a study plan to make sure you're fully prepared for any tests on this topic.\n"},"metadata":{}},{"output_type":"stream","name":"stdin","text":" exit\n"},{"name":"stdout","text":"ğŸ‘‹ Thatâ€™s a wrap for now! \n Great job today â€” every step you take brings you closer to your goals. ğŸ¯ \n Remember, Iâ€™m always here whenever you need help with studying, quizzes, or clearing up doubts. \n Stay curious, keep learning, and donâ€™t forget to take a break! ğŸ˜ŒğŸ“˜ \n See you soon...! ğŸŒŸ\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"### âœ… End Notes/Evaluation\nTo evaluate the model, we employed human feedback and a fine-tuning process that included a temperature parameter.","metadata":{}},{"cell_type":"markdown","source":"### ğŸ¤– Gen AI Intensive Course Capstone 2025Q1\n\nCapstone requirements: https://www.kaggle.com/competitions/gen-ai-intensive-course-capstone-2025q1\n\n### ğŸ§‘ğŸ½â€ğŸ’» Authors:\n- Rohan Vailala Thoma: [Kaggle-rohanthoma](https://www.kaggle.com/rohanthoma) | [LinkedIn](https://www.linkedin.com/in/rohan-vailala-thoma/)\n- Aditya Suryawanshi: [Kaggle-adii14](https://www.kaggle.com/adii14) \n- Harshitha: [Kaggle-harsh1tha](https://www.kaggle.com/harsh1tha) ","metadata":{}}]}